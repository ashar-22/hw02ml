# hw02ml
# Kaggle IEEE-CIS Fraud Detection Competition

## ○ მიმოხილვა
  ეს კონკურსი მიზნად ისახავდა ონლაინ თაღლითობის (fraud) აღმოჩენას სხვადასხვა ტრანზაქციის მახასიათებლების მიხედვით. მოცემული გვქონდა ორი ფაილი train_transaction.csv და train_identity.csv, რომელში მოცემული დატასეტის     წაკითხვის და ანალიზის შედეგად უნდა შეგვძლებოდა ისეთი მოდელის შექმნა, რომელიც შეძლებდა სავარაუდო თაღლითური ტრანზაქციების პროგნოზირებას მაქსიმალური სიზუსტით. 

## ○ ჩემი მიდგომა
  თავდაპირვველად გადავწყვიტე, გამეერთიანებინა ეს ორი დატასეტი საერთო სვეტის, Transaction_ID-ის მიხედვით და მასზე ჩამეტარებინა სხვადასხვა ოპერაცია: Feature Engineering, Feature Selection და Training, თუმცა მანამდე დავყავი 
  გაერთიანებული დატასეტი 60/20/20 შეფარდებით სამ ნაწილად: train, validation და test. ვალიდაციის ნაწილის ცალკე გამოყოფა დაგვეხმარება overfitting-ის თავიდან ასაცილებლად. 

## რეპოზიტორიის სტრუქტურა
  ○ model_experiment_log_reg.ipynb - Logistic Regression
  ○ model_experiment_xgboost.ipynb - XGBoost
  ○ model_experiment_adaboost.ipynb - AdaBoost 
  ○ model_experiment_random_forest.ipynb - Random Forest
  ○ model_inference.ipynb - მოდელის ჩამოტვირთვა MLflow-დან და სატესტო მონაცემებზე პროგნოზირებისთვის submission file-ის დაგენერირება

## Feature Engineering
 ### კატეგორიული ცვლადების რიცხვითში გადაყვანა
  გამოვიყენე OneHotEncoder და OrdinalEncoder categorical column-ების რიცხვით მნიშვნელობებში გადასაყვანად.
 ### Nan მნიშვნელობების დამუშავება
  Numerical ცვლადები შევცვალე მედიანით ან საშუალოთი და შედეგების მიხედვით სხვადასხვა მოდელში სხვა მნიშვნელობით შევცვალე, თუმცა მათ მიერ პროგნოზირებული შედეგები ძალიან მსგავსი იყო. categorical ტიპის სვეტებში Nan მნიშვნელობები ჩავანაცვლე სვეტში ყველაზე ხშირი მონაცემით(მოდათი).
 ### Cleaning 
  წავშალე ისეთი სვეტები, რომლებშიც Nan მნიშვნელობების რაოდენობა ზედმეტად ჭარბი იყო(მეტი threshold-ზე, რომელიც დავაფიქსირე, როგორც 0.6, 0.7, 0.75, 0.8). ექსპერიმენტების ჩატარებისას აღმოჩნდა, რომ threshold-ის შეცვლა არ ცვლიდა წაშლილი სვეტების რაოდენობას, ანუ არ არსებობდა ისეთი სვეტები, რომელთა Nan მნიშნელობების რაოდენობაც იყო 0.6-0.8 რეინჯში(იმავე პასუხს ვიღებდი ორივე threshold-ის შემთხვევაში).

## Feature Selection
  გამოვიყენე სამი მიდგომა:       VarianceThreshold — დაბალი ვარიაციის მქონე სვეტების მოცილება.
                                SelectKBest — საუკეთესო k სვეტის არჩევა (f_classif score).
                                Correlation - კორელაციის მატრიცის აგება(თუმცა ეს უკანასკნელი მეტ დროს საჭიროებდა და უკეთეს შედეგს არ აბრუნებდა და ვერც საუკეთესო მოდელის შექმნაში მიიღო მონაწილეობა)

## Training
  ○ ტესტირებული მოდელები: Logistic Regression, XGBoost, AdaBoost და Random Forest. 
  ○ მცირე დიაპაზონში, ხელით შერჩეული ჰიპერპარამეტრების ცდა (GridSearchCV ზოგი მოდელის შემთხვევაში, სხვა მოდელებისთვის კი ხელით ვარჩევდი პარამეტრებს: threshold-ს, k_best-ის k პარამეტრს, max_iteration-ს და შესაბამისი მოდელისთვის გადასაცემ სხვადასხვა პარამეტრს. მაგალითისთვის, Random Forest-ისთვის იცვლებოდა n_estimators და max_depth, Logistic Regression-ისთვის კი C (0.1, 1, 10).
  ○ საბოლოოდ დავლოგე ყველა ტესტირებული მოდელისთვის შესაბამისი საუკეთესო მოდელი ოპტიმალური პარამეტრებით(რომლებიც დალოგილია mlflow-ზე). მოდელები შევაფასე AUC მეტრიკით (val_auc , train_auc). ყველაზე მეტი ექსპერიმენტი xgboost-ისთვის ჩავატარე და ბევრი პარამეტრი მოვსინჯე, ალბათ, სწორედ ამიტომ, ამ მოდელმა საუკეთესო შედეგი მომცა. არ ახასიათებდა არც overfitting, არც underfitting. პარამეტრები:
 
  რაც შეეხება საბოლოო პროგნოზს ტესტზე, იხილეთ ლინკზე ყველა სხვა პროგნოზთან ერთად:  https://www.kaggle.com/competitions/ieee-fraud-detection/submissions# 

## MlFlow Tracking
 ექსპერიმენტები: https://dagshub.com/ashar-22/hw02ml/experiments
 
 ### დალოგილი პარამეტრები:

ჩinitial_missing_ratio — მონაცემების საშუალო NaN წილი ტრენინგის დასაწყისში.

drop_threshold — NaN მნიშვნელობების საფუძველზე სვეტების წაშლის ზღვარი.

num_cols_dropped — წაშლილი სვეტების რაოდენობა NaN წილის გამო.

missing_threshold — NaN წილის დამატებითი ზღვარი სხვა წაშლის პროცესისთვის.

dropped_columns_count — ამ პროცესში წაშლილი სვეტების რაოდენობა.

dropped_columns — წაშლილი სვეტების კონკრეტული სახელების ჩამონათვალი.

numerical_cols_count — რიცხვითი (Numerical) სვეტების რაოდენობა მონაცემებში.

categorical_cols_count — კატეგორიული (Categorical) სვეტების რაოდენობა მონაცემებში.

numerical_cols — გამოყენებული რიცხვითი სვეტების ჩამონათვალი.

categorical_cols — გამოყენებული კატეგორიული სვეტების ჩამონათვალი.

new_features — Feature Engineering-ის შედეგად დამატებული ახალი მახასიათებლები.
(მაგალითად: TransactionAmt_log.)

num_selected_features — Feature Selection-ის შედეგად დარჩენილი სვეტების რაოდენობა.

selected_features — Feature Selection-ის შემდეგ შერჩეული სვეტების სახელები (მძიმით გამოყოფილი string-ად).

k — SelectKBest გამოყენებისას არჩეული საუკეთესო სვეტების რაოდენობა.

model — გამოყენებული მოდელის ტიპი (მაგალითად, LogisticRegression, AdaBoostClassifier და სხვ.)

max_iter — Logistic Regression-ში გამოყენებული მაქსიმალური იტერაციების რაოდენობა.

### მეტრიკები:

train_accuracy — ტრენინგის მონაცემებზე მიღებული სიზუსტე (Accuracy).

val_accuracy — ვალიდაციის მონაცემებზე მიღებული სიზუსტე.

train_f1 — ტრენინგის მონაცემებზე მიღებული F1-score.

val_f1 — ვალიდაციის მონაცემებზე მიღებული F1-score.

train_auc — ტრენინგის მონაცემებზე მიღებული AUC მეტრიკა (Area Under ROC Curve).

val_auc — ვალიდაციის მონაცემებზე მიღებული AUC მეტრიკა.

### საუკეთესო მოდელი
  როგორც უკვე ვახსენე, ყველაზე მეტი ექსპერიმენტი xgboost-ისთვის ჩავატარე და ბევრი პარამეტრი მოვსინჯე, ალბათ, სწორედ ამიტომ, ამ მოდელმა საუკეთესო შედეგი მომცა. არ ახასიათებდა არც overfitting, არც underfitting.         
  პარამეტრები:
   
  classifier__learning_rate: 0.1
  classifier__max_depth: 6              
  classifier__n_estimators: 200          
  k: 150
  threshold: 0.75                         train_auc:  0.9349695289583454
  numerical to mean                       valid_auc:  0.9214822898654824
  
  (ზოგი პარამეტრი მოგვიანებით დავამატე დასალოგად, ამიტომ მხოლოდ საბმიშენ ფაილის აღწერაში მაქვს მითითებული)
