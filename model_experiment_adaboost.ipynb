{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":14242,"databundleVersionId":568274,"sourceType":"competition"}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-27T18:52:21.753260Z","iopub.execute_input":"2025-04-27T18:52:21.753636Z","iopub.status.idle":"2025-04-27T18:52:22.226722Z","shell.execute_reply.started":"2025-04-27T18:52:21.753600Z","shell.execute_reply":"2025-04-27T18:52:22.225715Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/ieee-fraud-detection/sample_submission.csv\n/kaggle/input/ieee-fraud-detection/test_identity.csv\n/kaggle/input/ieee-fraud-detection/train_identity.csv\n/kaggle/input/ieee-fraud-detection/test_transaction.csv\n/kaggle/input/ieee-fraud-detection/train_transaction.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import mlflow\nimport mlflow.sklearn\nimport pandas as pd\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import accuracy_score, roc_auc_score\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.compose import make_column_selector\nfrom sklearn.feature_selection import VarianceThreshold, SelectKBest, f_classif\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nimport numpy as np\nimport dagshub\n\ndagshub.init(repo_owner='ashar-22', repo_name='hw02ml', mlflow=True)\nexperiment_name = 'AdaBoost_experiment'\nmlflow.set_experiment(experiment_name)\n\ntrain_identity = pd.read_csv('/kaggle/input/ieee-fraud-detection/train_identity.csv')\ntrain_transaction = pd.read_csv('/kaggle/input/ieee-fraud-detection/train_transaction.csv')\n\ntrain = pd.merge(train_transaction, train_identity, on='TransactionID', how='left')\n\nfeatures = [col for col in train.columns if col not in [\"TransactionID\", \"isFraud\"]]\nX = train[features]\ny = train[\"isFraud\"]\n\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T18:52:25.851401Z","iopub.execute_input":"2025-04-27T18:52:25.851990Z","iopub.status.idle":"2025-04-27T18:53:10.319444Z","shell.execute_reply.started":"2025-04-27T18:52:25.851955Z","shell.execute_reply":"2025-04-27T18:53:10.318461Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Accessing as ashar-\u001b[1;36m22\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as ashar-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Initialized MLflow to track repo \u001b[32m\"ashar-22/hw02ml\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"ashar-22/hw02ml\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Repository ashar-\u001b[1;36m22\u001b[0m/hw02ml initialized!\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository ashar-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22</span>/hw02ml initialized!\n</pre>\n"},"metadata":{}}],"execution_count":2},{"cell_type":"markdown","source":"# Data Cleaning","metadata":{}},{"cell_type":"code","source":"with mlflow.start_run(run_name=\"LogReg_Cleaning\"):\n    threshold = 0.75\n    \n    missing_ratio = X_train.isnull().mean()\n    cols_to_drop = missing_ratio[missing_ratio > threshold].index.tolist()\n    X_train.drop(columns=cols_to_drop, inplace=True)\n    X_valid.drop(columns=cols_to_drop, inplace=True)\n    \n    mlflow.log_metric(\"initial_missing_ratio\", missing_ratio.mean())\n    mlflow.log_param(\"drop_threshold\", threshold)\n    mlflow.log_param(\"num_cols_dropped\", len(cols_to_drop))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T18:53:12.840955Z","iopub.execute_input":"2025-04-27T18:53:12.841224Z","iopub.status.idle":"2025-04-27T18:53:14.378344Z","shell.execute_reply.started":"2025-04-27T18:53:12.841200Z","shell.execute_reply":"2025-04-27T18:53:14.377463Z"}},"outputs":[{"name":"stdout","text":"üèÉ View run LogReg_Cleaning at: https://dagshub.com/ashar-22/hw02ml.mlflow/#/experiments/2/runs/9686c090910942d3bc04e7ba468f551c\nüß™ View experiment at: https://dagshub.com/ashar-22/hw02ml.mlflow/#/experiments/2\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"# Feature Engineering","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.pipeline import Pipeline, FunctionTransformer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.feature_selection import SelectKBest, f_classif\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_auc_score\n\n# numerical_cols = X_train.select_dtypes(include=np.number).columns.tolist()\n# categorical_cols = X_train.select_dtypes(include=['object']).columns.tolist()\n\nwith mlflow.start_run(run_name=\"adaboost_Engineering\"):\n    def add_transaction_amt_log(X):\n        X = X.copy()\n        if \"TransactionAmt\" in X.columns:\n            X[\"TransactionAmt_log\"] = np.log1p(X[\"TransactionAmt\"])\n        return X\n\n    log_transformer = FunctionTransformer(add_transaction_amt_log, validate=False)\n\n    numerical_cols = [col for col in X_train.columns if X_train[col].dtype in ['int64', 'float64']]\n    categorical_cols = [col for col in X_train.columns if X_train[col].dtype == 'object']\n    \n    numerical_transformer = Pipeline([\n        (\"imputer\", SimpleImputer(strategy=\"median\")),  # Impute missing values with the median for numerical features\n        (\"scaler\", StandardScaler())  # Apply scaling\n    ])\n  #   mlflow.log_param(\"strategy for nums\". \"median\")    \n    categorical_transformer = Pipeline([\n        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),  # Impute missing values with the most frequent category\n        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))  # Apply one-hot encoding\n    ])\n\n\n    if \"TransactionAmt\" in numerical_cols:\n        mlflow.log_param(\"new_features\", \"TransactionAmt_log\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T18:53:47.012935Z","iopub.execute_input":"2025-04-27T18:53:47.013315Z","iopub.status.idle":"2025-04-27T18:53:47.319824Z","shell.execute_reply.started":"2025-04-27T18:53:47.013288Z","shell.execute_reply":"2025-04-27T18:53:47.318720Z"}},"outputs":[{"name":"stdout","text":"üèÉ View run adaboost_Engineering at: https://dagshub.com/ashar-22/hw02ml.mlflow/#/experiments/2/runs/de71d58632ab478ab1aa74609116881d\nüß™ View experiment at: https://dagshub.com/ashar-22/hw02ml.mlflow/#/experiments/2\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"# Feature Selection","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_selection import VarianceThreshold, SelectKBest, f_classif\nimport numpy as np\nimport mlflow\n\nwith mlflow.start_run(run_name=\"adaboost_Feature_Selection\"):\n    variance_threshold = VarianceThreshold(threshold=0.01)  # Adjust threshold as needed\n    X_train_variance_filtered = variance_threshold.fit_transform(X_train[numerical_cols].fillna(0))\n\n    remaining_numerical_cols = np.array(numerical_cols)[variance_threshold.get_support()]\n\n    k_best = 70\n    selector = SelectKBest(score_func=f_classif, k=k_best)\n    selector.fit(X_train_variance_filtered, y_train)\n\n    selected_features = remaining_numerical_cols[selector.get_support()].tolist()\n\n    if \"TransactionAmt\" in selected_features:\n        selected_features.append(\"TransactionAmt_log\")\n\n    mlflow.log_param(\"num_selected_features\", len(selected_features))\n    mlflow.log_param(\"selected_features\", \", \".join(selected_features))\n    mlflow.log_param(\"k\", k)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T18:53:51.697204Z","iopub.execute_input":"2025-04-27T18:53:51.697571Z","iopub.status.idle":"2025-04-27T18:53:56.362489Z","shell.execute_reply.started":"2025-04-27T18:53:51.697544Z","shell.execute_reply":"2025-04-27T18:53:56.361316Z"}},"outputs":[{"name":"stdout","text":"üèÉ View run adaboost_Feature_Selection at: https://dagshub.com/ashar-22/hw02ml.mlflow/#/experiments/2/runs/bf36702a1cfb4847a1a2d66796ac7587\nüß™ View experiment at: https://dagshub.com/ashar-22/hw02ml.mlflow/#/experiments/2\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import roc_auc_score\nimport mlflow\nimport mlflow.sklearn\n\npreprocessor = ColumnTransformer([\n    (\"num\", numerical_transformer, numerical_cols),\n    (\"cat\", categorical_transformer, categorical_cols)\n])\n\n# Define the base estimator (a simple decision tree with max_depth=1)\nbase_model = DecisionTreeClassifier(max_depth=1, random_state=42)\n\n# Define the AdaBoost model using the base estimator\nadaboost = AdaBoostClassifier(base_model, n_estimators=100, learning_rate=0.1)\n\npipeline = Pipeline([\n    (\"preprocessor\", preprocessor),  # Handle missing values here\n    (\"classifier\", adaboost)         # AdaBoost classifier\n])\n\n# Train the model with the preprocessor in the pipeline\nwith mlflow.start_run(run_name=\"adaboost_Training\"):\n    pipeline.fit(X_train, y_train)\n\n    y_train_pred = pipeline.predict_proba(X_train)[:, 1]\n    y_valid_pred = pipeline.predict_proba(X_valid)[:, 1]\n\n    train_auc = roc_auc_score(y_train, y_train_pred)\n    valid_auc = roc_auc_score(y_valid, y_valid_pred)\n\n    mlflow.log_metrics({\"train_auc\": train_auc, \"valid_auc\": valid_auc})\n    mlflow.sklearn.log_model(pipeline, \"fraud_pipeline_adaboost\")\n\n    print(f\"Train AUC: {train_auc:.4f}\")\n    print(f\"Validation AUC: {valid_auc:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T18:55:09.730632Z","iopub.execute_input":"2025-04-27T18:55:09.731006Z"}},"outputs":[],"execution_count":null}]}