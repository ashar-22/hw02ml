{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":14242,"databundleVersionId":568274,"sourceType":"competition"}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-27T18:05:15.838847Z","iopub.execute_input":"2025-04-27T18:05:15.839438Z","iopub.status.idle":"2025-04-27T18:05:15.848592Z","shell.execute_reply.started":"2025-04-27T18:05:15.839398Z","shell.execute_reply":"2025-04-27T18:05:15.847246Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/ieee-fraud-detection/sample_submission.csv\n/kaggle/input/ieee-fraud-detection/test_identity.csv\n/kaggle/input/ieee-fraud-detection/train_identity.csv\n/kaggle/input/ieee-fraud-detection/test_transaction.csv\n/kaggle/input/ieee-fraud-detection/train_transaction.csv\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import mlflow\nimport mlflow.sklearn\nimport pandas as pd\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import accuracy_score, roc_auc_score\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.compose import make_column_selector\nfrom sklearn.feature_selection import VarianceThreshold, SelectKBest, f_classif\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nimport numpy as np\nimport dagshub\n\n# 1. Set up MLflow experiment\ndagshub.init(repo_owner='ashar-22', repo_name='hw02ml', mlflow=True)\nexperiment_name = 'logreg_experiment'\nmlflow.set_experiment(experiment_name)\n\ntrain_identity = pd.read_csv('/kaggle/input/ieee-fraud-detection/train_identity.csv')\ntrain_transaction = pd.read_csv('/kaggle/input/ieee-fraud-detection/train_transaction.csv')\n# test_identity = pd.read_csv('/kaggle/input/ieee-fraud-detection/test_identity.csv')\n# test_transaction = pd.read_csv('/kaggle/input/ieee-fraud-detection/test_transaction.csv')\n\ntrain = pd.merge(train_transaction, train_identity, on='TransactionID', how='left')\n# test = pd.merge(test_transaction, test_identity, on='TransactionID', how='left')\n\nfeatures = [col for col in train.columns if col not in [\"TransactionID\", \"isFraud\"]]\nX = train[features]\ny = train[\"isFraud\"]\n\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T18:05:18.175284Z","iopub.execute_input":"2025-04-27T18:05:18.175598Z","iopub.status.idle":"2025-04-27T18:05:55.278943Z","shell.execute_reply.started":"2025-04-27T18:05:18.175575Z","shell.execute_reply":"2025-04-27T18:05:55.277646Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Accessing as ashar-\u001b[1;36m22\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as ashar-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Initialized MLflow to track repo \u001b[32m\"ashar-22/hw02ml\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"ashar-22/hw02ml\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Repository ashar-\u001b[1;36m22\u001b[0m/hw02ml initialized!\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository ashar-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22</span>/hw02ml initialized!\n</pre>\n"},"metadata":{}}],"execution_count":3},{"cell_type":"markdown","source":"# Data Cleaning","metadata":{}},{"cell_type":"code","source":"with mlflow.start_run(run_name=\"LogReg_Cleaning\"):\n    threshold = 0.75\n    \n    missing_ratio = X_train.isnull().mean()\n    cols_to_drop = missing_ratio[missing_ratio > threshold].index.tolist()\n    X_train.drop(columns=cols_to_drop, inplace=True)\n    X_valid.drop(columns=cols_to_drop, inplace=True)\n    \n    mlflow.log_metric(\"initial_missing_ratio\", missing_ratio.mean())\n    mlflow.log_param(\"drop_threshold\", threshold)\n    mlflow.log_param(\"num_cols_dropped\", len(cols_to_drop))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T18:06:03.424529Z","iopub.execute_input":"2025-04-27T18:06:03.424935Z","iopub.status.idle":"2025-04-27T18:06:09.420936Z","shell.execute_reply.started":"2025-04-27T18:06:03.424898Z","shell.execute_reply":"2025-04-27T18:06:09.419641Z"}},"outputs":[{"name":"stdout","text":"üèÉ View run LogReg_Cleaning at: https://dagshub.com/ashar-22/hw02ml.mlflow/#/experiments/0/runs/414d7d037287495382d182a301e4e686\nüß™ View experiment at: https://dagshub.com/ashar-22/hw02ml.mlflow/#/experiments/0\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"# Feature Engineering","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.pipeline import Pipeline, FunctionTransformer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.feature_selection import SelectKBest, f_classif\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_auc_score\n\nnumerical_cols = X_train.select_dtypes(include=np.number).columns.tolist()\ncategorical_cols = X_train.select_dtypes(include=['object']).columns.tolist()\n\nwith mlflow.start_run(run_name=\"LogReg_Feature_Engineering\"):\n    def add_transaction_amt_log(X):\n        X = X.copy()\n        if \"TransactionAmt\" in X.columns:\n            X[\"TransactionAmt_log\"] = np.log1p(X[\"TransactionAmt\"])\n        return X\n\n    log_transformer = FunctionTransformer(add_transaction_amt_log, validate=False)\n\n    numerical_cols = [col for col in X_train.columns if X_train[col].dtype in ['int64', 'float64']]\n    categorical_cols = [col for col in X_train.columns if X_train[col].dtype == 'object']\n    \n    numerical_transformer = Pipeline([\n        (\"imputer\", SimpleImputer(strategy=\"median\")),  # Impute missing values with the median for numerical features\n        (\"scaler\", StandardScaler())  # Apply scaling\n    ])\n    \n    categorical_transformer = Pipeline([\n        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),  # Impute missing values with the most frequent category\n        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))  # Apply one-hot encoding\n    ])\n\n\n    if \"TransactionAmt\" in numerical_cols:\n        mlflow.log_param(\"new_features\", \"TransactionAmt_log\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T18:06:13.279270Z","iopub.execute_input":"2025-04-27T18:06:13.279648Z","iopub.status.idle":"2025-04-27T18:06:13.951970Z","shell.execute_reply.started":"2025-04-27T18:06:13.279621Z","shell.execute_reply":"2025-04-27T18:06:13.950735Z"}},"outputs":[{"name":"stdout","text":"üèÉ View run LogReg_Feature_Engineering at: https://dagshub.com/ashar-22/hw02ml.mlflow/#/experiments/0/runs/0cf6aa7359d54a22b161320983049cc6\nüß™ View experiment at: https://dagshub.com/ashar-22/hw02ml.mlflow/#/experiments/0\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"# Feature Selection","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_selection import VarianceThreshold, SelectKBest, f_classif\nimport numpy as np\nimport mlflow\n\nwith mlflow.start_run(run_name=\"LogReg_Feature_Selection\"):\n    variance_threshold = VarianceThreshold(threshold=0.01)  # Adjust threshold as needed\n    X_train_variance_filtered = variance_threshold.fit_transform(X_train[numerical_cols].fillna(0))\n\n    remaining_numerical_cols = np.array(numerical_cols)[variance_threshold.get_support()]\n\n    k_best = 90\n    selector = SelectKBest(score_func=f_classif, k=k_best)\n    selector.fit(X_train_variance_filtered, y_train)\n\n    selected_features = remaining_numerical_cols[selector.get_support()].tolist()\n\n    if \"TransactionAmt\" in selected_features:\n        selected_features.append(\"TransactionAmt_log\")\n\n    mlflow.log_param(\"num_selected_features\", len(selected_features))\n    mlflow.log_param(\"selected_features\", \", \".join(selected_features))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T18:06:20.965282Z","iopub.execute_input":"2025-04-27T18:06:20.965650Z","iopub.status.idle":"2025-04-27T18:06:25.838376Z","shell.execute_reply.started":"2025-04-27T18:06:20.965625Z","shell.execute_reply":"2025-04-27T18:06:25.836797Z"}},"outputs":[{"name":"stdout","text":"üèÉ View run LogReg_Feature_Selection at: https://dagshub.com/ashar-22/hw02ml.mlflow/#/experiments/0/runs/9a2e486473f444d1bfd0a16caa553d66\nüß™ View experiment at: https://dagshub.com/ashar-22/hw02ml.mlflow/#/experiments/0\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.metrics import roc_auc_score\nimport mlflow\n\npreprocessor = ColumnTransformer([\n    (\"num\", numerical_transformer, numerical_cols),\n    (\"cat\", categorical_transformer, categorical_cols)\n])\n\nlr = LogisticRegression(random_state=42, max_iter=1000)\n\npipeline = Pipeline([\n    (\"preprocessor\", preprocessor),\n    (\"classifier\", lr)\n])\n\nwith mlflow.start_run(run_name=\"logReg_Training\"):\n    pipeline.fit(X_train, y_train)\n\n    y_train_pred = pipeline.predict_proba(X_train)[:, 1]\n    y_valid_pred = pipeline.predict_proba(X_valid)[:, 1]\n\n    train_auc = roc_auc_score(y_train, y_train_pred)\n    valid_auc = roc_auc_score(y_valid, y_valid_pred)\n\n    mlflow.log_metrics({\"train_auc\": train_auc, \"valid_auc\": valid_auc})\n\n    mlflow.sklearn.log_model(pipeline, \"fraud_pipeline\")\n\n    print(f\"Train AUC: {train_auc:.4f}\")\n    print(f\"Validation AUC: {valid_auc:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T18:06:50.372509Z","iopub.execute_input":"2025-04-27T18:06:50.372896Z","iopub.status.idle":"2025-04-27T18:10:44.394366Z","shell.execute_reply.started":"2025-04-27T18:06:50.372869Z","shell.execute_reply":"2025-04-27T18:10:44.393006Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n\u001b[31m2025/04/27 18:10:41 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Train AUC: 0.8452\nValidation AUC: 0.8409\nüèÉ View run logReg_Training at: https://dagshub.com/ashar-22/hw02ml.mlflow/#/experiments/0/runs/c8df10b9d6f54d87a305d55ad6066f5d\nüß™ View experiment at: https://dagshub.com/ashar-22/hw02ml.mlflow/#/experiments/0\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}