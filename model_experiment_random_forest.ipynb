{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":14242,"databundleVersionId":568274,"sourceType":"competition"}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-27T21:37:55.893332Z","iopub.execute_input":"2025-04-27T21:37:55.893884Z","iopub.status.idle":"2025-04-27T21:37:55.900181Z","shell.execute_reply.started":"2025-04-27T21:37:55.893859Z","shell.execute_reply":"2025-04-27T21:37:55.899291Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/ieee-fraud-detection/sample_submission.csv\n/kaggle/input/ieee-fraud-detection/test_identity.csv\n/kaggle/input/ieee-fraud-detection/train_identity.csv\n/kaggle/input/ieee-fraud-detection/test_transaction.csv\n/kaggle/input/ieee-fraud-detection/train_transaction.csv\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import mlflow\nimport mlflow.sklearn\nimport pandas as pd\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import accuracy_score, roc_auc_score\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.compose import make_column_selector\nfrom sklearn.feature_selection import VarianceThreshold, SelectKBest, f_classif\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nimport numpy as np\nimport dagshub\n\n# 1. Set up MLflow experiment\ndagshub.init(repo_owner='ashar-22', repo_name='hw02ml', mlflow=True)\nexperiment_name = 'rf_experiment'\nmlflow.set_experiment(experiment_name)\n\ntrain_identity = pd.read_csv('/kaggle/input/ieee-fraud-detection/train_identity.csv')\ntrain_transaction = pd.read_csv('/kaggle/input/ieee-fraud-detection/train_transaction.csv')\n# test_identity = pd.read_csv('/kaggle/input/ieee-fraud-detection/test_identity.csv')\n# test_transaction = pd.read_csv('/kaggle/input/ieee-fraud-detection/test_transaction.csv')\n\ntrain = pd.merge(train_transaction, train_identity, on='TransactionID', how='left')\n# test = pd.merge(test_transaction, test_identity, on='TransactionID', how='left')\n\nfeatures = [col for col in train.columns if col not in [\"TransactionID\", \"isFraud\"]]\nX = train[features]\ny = train[\"isFraud\"]\n\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T21:38:31.391692Z","iopub.execute_input":"2025-04-27T21:38:31.392348Z","iopub.status.idle":"2025-04-27T21:39:04.307631Z","shell.execute_reply.started":"2025-04-27T21:38:31.392320Z","shell.execute_reply":"2025-04-27T21:39:04.306682Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Accessing as ashar-\u001b[1;36m22\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as ashar-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Initialized MLflow to track repo \u001b[32m\"ashar-22/hw02ml\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"ashar-22/hw02ml\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Repository ashar-\u001b[1;36m22\u001b[0m/hw02ml initialized!\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository ashar-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22</span>/hw02ml initialized!\n</pre>\n"},"metadata":{}}],"execution_count":3},{"cell_type":"markdown","source":"# Data Cleaning","metadata":{}},{"cell_type":"code","source":"with mlflow.start_run(run_name=\"rf_Cleaning\"):\n    threshold = 0.75\n    \n    missing_ratio = X_train.isnull().mean()\n    cols_to_drop = missing_ratio[missing_ratio > threshold].index.tolist()\n    X_train.drop(columns=cols_to_drop, inplace=True)\n    X_valid.drop(columns=cols_to_drop, inplace=True)\n    \n    mlflow.log_metric(\"initial_missing_ratio\", missing_ratio.mean())\n    mlflow.log_param(\"drop_threshold\", threshold)\n    mlflow.log_param(\"num_cols_dropped\", len(cols_to_drop))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T21:43:22.273101Z","iopub.execute_input":"2025-04-27T21:43:22.273503Z","iopub.status.idle":"2025-04-27T21:43:24.630188Z","shell.execute_reply.started":"2025-04-27T21:43:22.273475Z","shell.execute_reply":"2025-04-27T21:43:24.629234Z"}},"outputs":[{"name":"stdout","text":"üèÉ View run rf_Cleaning at: https://dagshub.com/ashar-22/hw02ml.mlflow/#/experiments/4/runs/783e30abcfaa484691b09a193bcd39d0\nüß™ View experiment at: https://dagshub.com/ashar-22/hw02ml.mlflow/#/experiments/4\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"# Feature Engineering","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.pipeline import Pipeline, FunctionTransformer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.feature_selection import SelectKBest, f_classif\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_auc_score\n\nnumerical_cols = X_train.select_dtypes(include=np.number).columns.tolist()\ncategorical_cols = X_train.select_dtypes(include=['object']).columns.tolist()\n\nwith mlflow.start_run(run_name=\"rf_Feature_Engineering\"):\n    def add_transaction_amt_log(X):\n        X = X.copy()\n        if \"TransactionAmt\" in X.columns:\n            X[\"TransactionAmt_log\"] = np.log1p(X[\"TransactionAmt\"])\n        return X\n\n    log_transformer = FunctionTransformer(add_transaction_amt_log, validate=False)\n\n    numerical_cols = [col for col in X_train.columns if X_train[col].dtype in ['int64', 'float64']]\n    categorical_cols = [col for col in X_train.columns if X_train[col].dtype == 'object']\n    \n    numerical_transformer = Pipeline([\n        (\"imputer\", SimpleImputer(strategy=\"median\")),  # Impute missing values with the median for numerical features\n        (\"scaler\", StandardScaler())  # Apply scaling\n    ])\n    \n    categorical_transformer = Pipeline([\n        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),  # Impute missing values with the most frequent category\n        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))  # Apply one-hot encoding\n    ])\n\n\n    if \"TransactionAmt\" in numerical_cols:\n        mlflow.log_param(\"new_features\", \"TransactionAmt_log\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T21:43:31.970406Z","iopub.execute_input":"2025-04-27T21:43:31.970726Z","iopub.status.idle":"2025-04-27T21:43:32.649192Z","shell.execute_reply.started":"2025-04-27T21:43:31.970700Z","shell.execute_reply":"2025-04-27T21:43:32.648333Z"}},"outputs":[{"name":"stdout","text":"üèÉ View run rf_Feature_Engineering at: https://dagshub.com/ashar-22/hw02ml.mlflow/#/experiments/4/runs/3bda9d11971b46d79adaf774172135df\nüß™ View experiment at: https://dagshub.com/ashar-22/hw02ml.mlflow/#/experiments/4\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"# Feature Selection","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_selection import VarianceThreshold, SelectKBest, f_classif\nimport numpy as np\nimport mlflow\n\nwith mlflow.start_run(run_name=\"rf_Feature_Selection\"):\n    variance_threshold = VarianceThreshold(threshold=0.01)  # Adjust threshold as needed\n    X_train_variance_filtered = variance_threshold.fit_transform(X_train[numerical_cols].fillna(0))\n\n    remaining_numerical_cols = np.array(numerical_cols)[variance_threshold.get_support()]\n\n    k_best = 90\n    selector = SelectKBest(score_func=f_classif, k=k_best)\n    selector.fit(X_train_variance_filtered, y_train)\n\n    selected_features = remaining_numerical_cols[selector.get_support()].tolist()\n\n    if \"TransactionAmt\" in selected_features:\n        selected_features.append(\"TransactionAmt_log\")\n\n    mlflow.log_param(\"num_selected_features\", len(selected_features))\n    mlflow.log_param(\"selected_features\", \", \".join(selected_features))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T21:46:11.724935Z","iopub.execute_input":"2025-04-27T21:46:11.727258Z","iopub.status.idle":"2025-04-27T21:46:16.403308Z","shell.execute_reply.started":"2025-04-27T21:46:11.727191Z","shell.execute_reply":"2025-04-27T21:46:16.402331Z"}},"outputs":[{"name":"stdout","text":"üèÉ View run rf_Feature_Selection at: https://dagshub.com/ashar-22/hw02ml.mlflow/#/experiments/4/runs/e92e08b352274cad8a0707b4689544c5\nüß™ View experiment at: https://dagshub.com/ashar-22/hw02ml.mlflow/#/experiments/4\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.metrics import roc_auc_score\nimport mlflow\nimport mlflow.sklearn\n\n# Preprocessing (same as before)\npreprocessor = ColumnTransformer([\n    (\"num\", numerical_transformer, numerical_cols),\n    (\"cat\", categorical_transformer, categorical_cols)\n])\n\n# Define Random Forest model\nrf = RandomForestClassifier(\n    n_estimators=100, \n    max_depth=10,           # <-- Limit the depth\n    min_samples_split=5,    # <-- Require more samples to split\n    min_samples_leaf=3,     # <-- Each leaf must have at least 3 samples\n    random_state=42, \n    n_jobs=-1\n)\n\n# Build pipeline\npipeline = Pipeline([\n    (\"preprocessor\", preprocessor),\n    (\"classifier\", rf)\n])\n\n# Train and log with MLflow\nwith mlflow.start_run(run_name=\"RandomForest_Training\"):\n    pipeline.fit(X_train, y_train)\n\n    y_train_pred = pipeline.predict_proba(X_train)[:, 1]\n    y_valid_pred = pipeline.predict_proba(X_valid)[:, 1]\n\n    train_auc = roc_auc_score(y_train, y_train_pred)\n    valid_auc = roc_auc_score(y_valid, y_valid_pred)\n\n    mlflow.log_metrics({\"train_auc\": train_auc, \"valid_auc\": valid_auc})\n\n    mlflow.sklearn.log_model(pipeline, \"fraud_pipeline_rf\")\n\n    print(f\"Train AUC: {train_auc:.4f}\")\n    print(f\"Validation AUC: {valid_auc:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T21:46:19.305705Z","iopub.execute_input":"2025-04-27T21:46:19.306553Z","iopub.status.idle":"2025-04-27T21:48:05.151076Z","shell.execute_reply.started":"2025-04-27T21:46:19.306517Z","shell.execute_reply":"2025-04-27T21:48:05.149913Z"}},"outputs":[{"name":"stderr","text":"\u001b[31m2025/04/27 21:48:02 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Train AUC: 0.8871\nValidation AUC: 0.8774\nüèÉ View run RandomForest_Training at: https://dagshub.com/ashar-22/hw02ml.mlflow/#/experiments/4/runs/a40d6c535dab446bad77b7ac981248d8\nüß™ View experiment at: https://dagshub.com/ashar-22/hw02ml.mlflow/#/experiments/4\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}